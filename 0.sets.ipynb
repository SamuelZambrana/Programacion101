{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sets\n",
    "\n",
    "--------------------\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (0) Eliminar duplicados\n",
    "\n",
    "Tienes una lista con nombres de clientes y quieres la *lista de nombres únicos*. Usa un `set`. Crea la función `get_unique`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique(listado):\n",
    "    return list(set(listado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Antonio', 'Anakin', 'Juan', 'Pedro', 'Carlos', 'Sofía', 'Ana', 'Laura']\n"
     ]
    }
   ],
   "source": [
    "print(get_unique([\"Sofía\", \"Laura\", \"Anakin\", \"Carlos\", \"Antonio\",\"Pedro\", \"Ana\", \"Juan\", \"Carlos\", \"Anakin\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) Extraer palabras únicas\n",
    "\n",
    "Dada una cadena de texto, extrae todas las palabras únicas en esa cadena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"uno uno dos dos tres tres tres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique(strings):\n",
    "    unique_words=''\n",
    "    for element in set(strings.split(' ')):\n",
    "        unique_words = unique_words + element+ ' '\n",
    "    unique_words = unique_words[:-1]\n",
    "    return unique_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tres dos uno'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unique(texto)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Elementos en común\n",
    "\n",
    "Dadas dos listas de nombres, verifica si comparten algún nombre en común."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista1 = [\"Pedro\", \"Ana\", \"Juan\", \"Carlos\", \"Anakin\"]\n",
    "lista2 = [\"Sofía\", \"Laura\", \"Anakin\", \"Carlos\", \"Antonio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_comun_element(names1, names2):\n",
    "    for element in names1:\n",
    "        if element in names2:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_comun_element(lista1, lista2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commun_elements(names1, names2):\n",
    "    list_commun = []\n",
    "    for element in names1:\n",
    "        if element in names2:\n",
    "            list_commun.append(element)\n",
    "    uniquecommun = set(list_commun)\n",
    "    uniquecommun = list(uniquecommun)\n",
    "    \n",
    "    return uniquecommun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commun_elements2(names1, names2):\n",
    "    return set(names1).intersection(names2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Carlos', 'Anakin']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commun_elements(lista1, lista2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anakin', 'Carlos'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commun_elements2(lista1, lista2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (3) Elementos Únicos\n",
    "\n",
    "Crea una función que recibe una lista de elementos y te devuelve una lista de aquellos elementos únicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def once_element(elements):\n",
    "    uniques = set(elements)\n",
    "    no_repited = uniques.copy()\n",
    "    for item in uniques:\n",
    "        counter = 0\n",
    "        for element in elements:\n",
    "            if element == item:\n",
    "                counter = counter +1\n",
    "                if counter > 1:\n",
    "                    if element in no_repited:\n",
    "                        no_repited.remove(element)\n",
    "    return list(no_repited)\n",
    "                \n",
    "                \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_repeat_list(lista):\n",
    "    return list(set(lista))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'd', 'S', 'u', 'f', 'g']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "once_element(['S','u','p','e','r','c','a','l','i','f','r','a','g','i','l','i','s','t','i','c','o','e','s','p','i','i','d','o','s','o'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Antonio', 'Anakin', 'Juan', 'Pedro', 'Carlos', 'Sofía', 'Ana', 'Laura']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_repeat_list([\"Pedro\", \"Ana\", \"Juan\", \"Carlos\", \"Anakin\",\"Sofía\", \"Laura\", \"Anakin\", \"Carlos\", \"Antonio\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (4) Letras Únicas\n",
    "\n",
    "Crea la función que recibe una cadena, por ejemplo \"Supercalifragilisticoespialidoso\" y devuelve una lista con las letras únicas.\n",
    "\n",
    "Recuerda que una cadena es una secuencia (al igual que la lista). Quizás se puede convertir en un set.\n",
    "\n",
    "1. Prueba con \"Supercalifragilisticoespialidoso\". ¿Te has llevado alguna sorpresa?\n",
    "2. ¿Cómo lo arreglarías? ¿Recuerdas la normalización?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_letters(text):\n",
    "    return list(set(text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l', 'u', 'a', 'r', 's', 'g', 't', 'i', 'o', 'c', 'p', 'd', 'f', 'e']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_letters(\"Supercalifragilisticoespialidoso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def once_letters(text):\n",
    "    return once_element(list(text))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u', 'g', 't', 'S', 'd', 'f']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "once_letters(\"Supercalifragilisticoespialidoso\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (5) Los suspensos\n",
    "\n",
    "Dado un conjunto de estudiantes que aprobaron el examen de P101 y un conjunto de estudiantes que examinaron, identifica a los estudiantes que suspendieron.\n",
    "\n",
    "```Python\n",
    "aprobaron = {\"Pedro\", \"Ana\", \"Juan\"}\n",
    "tomaron_examen = {\"Pedro\", \"Ana\", \"Juan\", \"Carlos\", \"Luis\"}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_set(set1:list[str], set2:list[str])->list[str]:\n",
    "    suspensos = set()\n",
    "    for item in set1:\n",
    "        if item not in set2:\n",
    "            suspensos.add(item)\n",
    "            \n",
    "    return suspensos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_set2(set1:list[str], set2:list[str])->list[str]:\n",
    "    \n",
    "            \n",
    "    return set(set1).difference(set(set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Carlos', 'Luis'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aprobaron = {\"Pedro\", \"Ana\", \"Juan\"}\n",
    "tomaron_examen = {\"Pedro\", \"Ana\", \"Juan\", \"Carlos\", \"Luis\"}\n",
    "compare_set2(tomaron_examen,aprobaron)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (6) ¿Contiene vocales?\n",
    "\n",
    "Crea la función `contains_vowels(word:str)->bool` que recibe un texto y devuelve si contiene o no alguna vocal.\n",
    "\n",
    "Usa un `set` para representar las vocales."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (7) Palabras más comunes\n",
    "\n",
    "Crea la función `most_common_words` que recibe una cadena de texto y un `set` de [stop words](https://en.wikipedia.org/wiki/Stop_word). Devuelve un `set` con las palabras más comunes, exceptuando las *stopwords*.\n",
    "\n",
    "Las *stop words* son palabras muy comunes en un idioma y que no aportan mucho significado. Por eso son detenidas (stop) antes de ser procesadas por software de NLP (Natural Language Processing).\n",
    "\n",
    "Las listas de *stopwords* son específicas de cada idioma.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words comunes en inglés\n",
    "stopwords = {\n",
    "    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \n",
    "    \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \n",
    "    \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \n",
    "    \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \n",
    "    \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \n",
    "    \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \n",
    "    \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \n",
    "    \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \n",
    "    \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \n",
    "    \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \n",
    "    \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \n",
    "    \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \n",
    "    \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \n",
    "    \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \n",
    "    \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \n",
    "    \"should\", \"now\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba tu función con este texto:\n",
    "\n",
    "samuel_ipsum = \"\"\"\n",
    "Normally, both your asses would be dead as fucking fried chicken, but you happen to pull this shit while I'm in a transitional period so I don't wanna kill you, I wanna help you. But I can't give you this case, it don't belong to me. Besides, I've already been through too much shit this morning over this case to hand it over to your dumb ass.\n",
    "\n",
    "Now that we know who you are, I know who I am. I'm not a mistake! It all makes sense! In a comic, you know how you can tell who the arch-villain's going to be? He's the exact opposite of the hero. And most times they're friends, like you and me! I should've known way back when... You know why, David? Because of the kids. They called me Mr Glass.\n",
    "\n",
    "Look, just because I don't be givin' no man a foot massage don't make it right for Marsellus to throw Antwone into a glass motherfuckin' house, fuckin' up the way the nigger talks. Motherfucker do that shit to me, he better paralyze my ass, 'cause I'll kill the motherfucker, know what I'm sayin'?\n",
    "\n",
    "You think water moves fast? You should see ice. It moves like it has a mind. Like it knows it killed the world once and got a taste for murder. After the avalanche, it took us a week to climb out. Now, I don't know exactly when we turned on each other, but I know that seven of us survived the slide... and only five made it out. Now we took an oath, that I'm breaking now. We said we'd say it was the snow that killed the other two, but it wasn't. Nature is lethal but it doesn't hold a candle to man.\n",
    "\n",
    "Well, the way they make shows is, they make one show. That show's called a pilot. Then they show that show to the people who make shows, and on the strength of that one show they decide if they're going to make more shows. Some pilots get picked and become television programs. Some don't, become nothing. She starred in one of the ones that became nothing.\n",
    "\n",
    "My money's in that office, right? If she start giving me some bullshit about it ain't there, and we got to go someplace else and get it, I'm gonna shoot you in the head then and there. Then I'm gonna shoot that bitch in the kneecaps, find out where my goddamn money is. She gonna tell me too. Hey, look at me when I'm talking to you, motherfucker. You listen: we go in there, and that nigga Winston or anybody else is in there, you the first motherfucker to get shot. You understand?\n",
    "\n",
    "Your bones don't break, mine do. That's clear. Your cells react to bacteria and viruses differently than mine. You don't get sick, I do. That's also clear. But for some reason, you and I react the exact same way to water. We swallow it too fast, we choke. We get some in our lungs, we drown. However unreal it may seem, we are connected, you and I. We're on the same curve, just on opposite ends.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def txt_to_list_lower(text:str)->list[str]:\n",
    "    splitedlist = text.lower().split()\n",
    "    return list(splitedlist)\n",
    "def clean_puntuation(string_list:list[str])->list[str]:\n",
    "    return_list = []\n",
    "    for element in string_list:\n",
    "        if len(element) > 2 and element[-3] in ',...;:?!':\n",
    "            return_list.append(element[:-3])\n",
    "        elif element[-1] in ',...;:?!':\n",
    "            return_list.append(element[:-1])\n",
    "        else:\n",
    "            return_list.append(element)\n",
    "    return return_list\n",
    "\n",
    "def normalizedset(texto):\n",
    "    splited_text = txt_to_list_lower(texto)\n",
    "    splited_text = clean_puntuation(splited_text)\n",
    "    return set (splited_text)\n",
    "            \n",
    "def more_common_words(text, stopwords):\n",
    "    words = normalizedset(text)\n",
    "    \n",
    "    return set(words).difference(stopwords)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hold', 'already', 'hero', 'people', \"arch-villain's\", 'became', 'reason', 'get', 'glass', 'talks', \"that's\", 'world', 'knows', \"we'd\", 'makes', 'snow', 'taste', 'strength', 'house', 'hand', 'fast', 'tell', 'normally', 'friends', 'chicken', 'someplace', 'nothing', 'may', \"i've\", 'drown', 'shows', 'water', 'also', 'seven', \"doesn't\", 'help', 'make', 'called', 'well', 'see', 'talking', 'swallow', 'differently', 'show', 'decide', 'times', 'paralyze', 'find', 'unreal', 'us', 'week', 'go', 'asses', 'would', \"i'll\", 'first', 'david', 'ass', 'one', 'bitch', 'two', 'break', 'back', 'going', 'dumb', 'nigga', \"sayin'\", 'slide', 'kids', 'give', 'shoot', 'picked', 'choke', 'candle', 'fried', 'opposite', 'viruses', 'programs', \"money's\", \"ain't\", 'avalanche', 'bullshit', 'mine', 'money', 'comic', 'winston', 'goddamn', 'ones', 'pilots', 'think', 'right', 'got', 'five', 'office', \"fuckin'\", 'mind', 'shit', 'know', \"we're\", 'bones', 'case', 'pull', 'however', 'nigger', 'better', \"wasn't\", \"show's\", 'starred', 'cells', 'belong', 'connected', 'gonna', 'made', 'look', 'seem', 'kneecaps', 'lethal', 'mistake', 'giving', 'antwone', 'else', 'listen', \"can't\", \"they're\", 'besides', 'sick', 'transitional', 'clear', 'took', \"he's\", 'say', 'kill', 'ice', 'television', 'wanna', 'head', 'morning', 'exactly', 'killed', \"don't\", \"should've\", 'way', 'exact', 'oath', 'said', 'much', 'known', 'turned', 'hey', 'shot', 'sense', 'understand', 'foot', \"givin'\", 'period', 'become', 'start', 'mr', 'curve', 'pilot', 'man', 'fucking', 'motherfucker', 'moves', 'ends', 'lungs', 'survived', 'dead', 'react', \"motherfuckin'\", \"'cause\", 'like', 'massage', 'happen', 'marsellus', 'bacteria', 'climb', 'murder', 'anybody', 'breaking', 'nature', 'throw', \"i'm\"}\n"
     ]
    }
   ],
   "source": [
    "more_common_words(samuel_ipsum,stopwords)\n",
    "print(more_common_words(samuel_ipsum,stopwords))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Para transformar una cadena en una lista de *palabras*, puedes usar el método `split()` de una cadena. A esto se le llama *tokenizar* una cadena y es un procedimiento muy importante.\n",
    "2. Recuerda normalizar.\n",
    "3. ¿No habría que eliminar la puntuación? Una forma sencilla, sería dándose cuenta que en Inglés, la puntuación estará siempre al final de las palabras ys erá un símbolo. Es un símbolo de un *conjunto* limitado de símbolos (,.;:?!). ¿Lo pillas?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
